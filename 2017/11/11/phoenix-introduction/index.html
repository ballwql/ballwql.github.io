<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>【原】浅谈Phoenix在HBase中的应用 | ballen博客</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/7.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.2.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="stylesheet" type="text/css" href="/css/copyright.css?v=0.0.0"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">【原】浅谈Phoenix在HBase中的应用</h1><a id="logo" href="/.">ballen博客</a><p class="description">专注于智能运维&amp;大数据</p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div id="layout" class="pure-g"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">【原】浅谈Phoenix在HBase中的应用</h1><div class="post-meta">Nov 11, 2017<span> | </span><span class="category"><a href="/categories/HBase/">HBase</a></span><script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> 阅读</span></span></div><div class="post-content"><p>业务使用HBase已经有一段时间了，期间也反馈了很多问题，其中反馈最多的是HBase是否支持SQL查询和二级索引，由于HBase在这两块上目前暂不支持，导致业务在使用时无法更好的利用现有的经验来查询HBase。虽然HBase本身不支持SQL，但业界还是有现成的方案来支持，如Hive、Impala、Phoenix等。众多方案各有各的优势，本文主要对Phoenix作一个大概的介绍。<br><a id="more"></a></p>
<h1 id="一、介绍"><a href="#一、介绍" class="headerlink" title="一、介绍"></a>一、介绍</h1><p>Phoenix中文翻译为<code>凤凰</code>, 其最早是Salesforce的一个开源项目，Salesforce背景是一个搞ERP的，ERP软件一个很大的特点就是数据库操作，所以能搞出一个数据库中间件也是很正常的。而后，Phoenix成为Apache基金的顶级项目。</p>
<p>Phoenix具体是什么呢，其本质是用Java写的基于JDBC API操作HBase的开源SQL引擎。它有如下几个功能特性：</p>
<p><img src="/2017/11/11/phoenix-introduction/phoenix_characteristic.png" alt="图1.phoenix功能特性"></p>
<p>我觉得值得关注的几个特性主要有以下几块：</p>
<blockquote>
<ul>
<li>通过JDBC API实现了大部分的java.sql接口，包括元数据API</li>
<li>DDL支持：通过CREATE TABLE、DROP TABLE及ALTER TABLE来添加/删除</li>
<li>DML支持：用于逐行插入的UPSERT VALUES,用于相同或不同表之间大量数据传输的UPSERT SELECT,用于删除行的DELETE</li>
<li>事务支持：通过客户端的批处理实现的有限的事务支持(beta测试中)</li>
<li>二级索引支持：</li>
<li>遵循ANSI SQL标准</li>
</ul>
</blockquote>
<p>当前使用Phoenix的公司有很多，如下图所示：</p>
<p><img src="/2017/11/11/phoenix-introduction/phoenix_company.png" alt="图2.phoenix使用公司"></p>
<p>对于我们公司来说，虽然HBase用得多，但用Phoenix的比较少。从自己测试来看，Phoenix确实还存在各种不稳定，如下面描述的几点问题：</p>
<blockquote>
<ul>
<li>最新版本对HBase、Hadoop等有严格版本控制，对于已经用上HBase的业务来说要升级HBase版本适配Phoenix代价太大</li>
<li>与HBase强相关，作为HBase中的一个组件启动，HBase元数据容易遭到破坏</li>
<li>官方提供的创建索引方法，容易导致插入失败，查询失败，程序崩溃等问题</li>
</ul>
</blockquote>
<p>我觉得Phoenix总体思路还是很不错的，但本身太冒进，急于集成新功能，但现有的功能所存在的问题却并未有很好的解决方案，导致版本很多，但没有一个版本能放心在生产环境使用。下面关注一下Phoenix的整体设计思路。</p>
<h1 id="Phoenix架构"><a href="#Phoenix架构" class="headerlink" title="Phoenix架构"></a>Phoenix架构</h1><p>上面说到，Phoenix是以JDBC驱动方式嵌入到HBase中的，在部署时只有一个包，直接放HBase的lib目录，逻辑构架如下：</p>
<p><img src="/2017/11/11/phoenix-introduction/phoenix_structure.png" alt="图3.phoenix_structure"></p>
<p>从图中可看出，每个RS结点上，都会有一个Phoenix协处理器来处理每个表、每个region的数据，应用端通过Phoneix客户端与HBase客户端打交道，从而实现Sql化访问HBase数据。下面先来说下Coprocessor。</p>
<h2 id="2-1-Coprocessor"><a href="#2-1-Coprocessor" class="headerlink" title="2.1 Coprocessor"></a>2.1 Coprocessor</h2><p>HBase的协处理器主要受Google BigTable的影响，具体可参考<a href="http://www.scribd.com/doc/21631448/Dean-Keynote-Ladis2009" target="_blank" rel="external">Dean-Keynote-Ladis2009-page 66-67</a>。 对于HBase来说，引入Coprocessor也是为了提供更好的并行计算能力，而无需依赖于Hadoop的MapReduce。同时，基于Coprocessor，可以更好的实现二级索引、复杂过滤规则、权限访问控制等更接地气的特性。Coprocessor有两种类型，<code>Observer</code>和<code>EndPoint</code>。</p>
<p>前者Observer，类似于RDBMS的触发器，主要作用于RegionServer服务端，通过重载Coprocessor框架的Upcall函数插入用户自己的逻辑，这些逻辑只有在固定的事件发生时才会被触发调用执行，主要有三类hook接口：<code>RegionObserver</code>、<code>WALObserver</code>和<code>MasterObserver</code>。RegionObserver提供了一些数据层操作事件的hook,如Put、Get、Delete和Scan等，在每个操作发生或结束时，会触发调用一些前置的Hook(pre+操作,如preGet)或后置的Hook(post+操作,如postGet)；WALObserver提供了WAL相关的Hook；MasterObserver提供了HMaster相关的Hook。</p>
<p>后者EndPoint类似于RDBMS的存储过程，主要作用于客户端，客户端可以调用这些EndPoint执行一段Server端代码，并将Server端代码结果返回给客户端进一步处理，如常见聚合操作，找一张大表某个字段的最大值，如果不用Coprocesser则只能全表扫描，在客户端遍历所有结果找出最大值，且只能利用有限的客户端资源进行迭代计算，无法利用上HBase的并发计算能力；如果用了Coprocessor,则client端可在RegionServer端执行统计每个Region最大值的逻辑，并将Server端结果返回客户端，再找出所有Server端所返回的最大值中的最大值得到最终结果，很明显，这种方式尽量将统计执行下放到Server端，Client端只执行一些最后的聚合，大幅提高了统计效率;还有一个很常见的需求可能就是统计表的行数，其逻辑和上面一样,具体可参考<a href="https://blogs.apache.org/hbase/entry/coprocessor_introduction" target="_blank" rel="external">Coprocessor Introduction</a>,在这里就不展开了，后面有机会针对Coprocessor单独展开介绍。</p>
<h2 id="2-2-Phoenix-实现原理"><a href="#2-2-Phoenix-实现原理" class="headerlink" title="2.2 Phoenix 实现原理"></a>2.2 Phoenix 实现原理</h2><p>Phoenix的SQL实现原理主要也是基于一系列的Scan操作来完成，Scan是HBase的批量扫描过程。这一系列的Scan操作也是分散到各台RegionServer上通过Coprocessor来完成。主要用到的是RegionObserver，通过RegionObserver在postScannerOpen Hook中将RegionScanner替换成支持聚合操作的定制化Scanner，在真正执行聚合时，会通过自定的Scan属性传递给RegionScanner，在这个Scan中也可加入一些过滤规则，尽量减少返回Client的结果。</p>
<h2 id="2-3-Phoenix-数据模型"><a href="#2-3-Phoenix-数据模型" class="headerlink" title="2.3 Phoenix 数据模型"></a>2.3 Phoenix 数据模型</h2><p>Phoenix在数据模型上是将HBase非关系型形式转换成关系型数据模型    ，如下图所示<br><img src="/2017/11/11/phoenix-introduction/phoenix_data_model.png" alt="图4.Phoenix Data Model"><br>对于Phoenix来说，HBase的rowkey会被转换成primary key，column family如果不指定则为0否则字段名会带上，qualifier转换成表的字段名，如下是创建一个Phoenix表的例子，以创建表<code>test</code>为例，主键为<code>id</code>即为HBase的rowkey, column family为<code>i</code>, qualifier为name和age。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">create table &quot;test&quot; (&quot;id&quot; varchar(20) primary key,&quot;i&quot;.&quot;name&quot; varchar(20) ,&quot;i&quot;.&quot;age&quot; varchar(20));</div></pre></td></tr></table></figure></p>
<p>Phoenix还支持组合primary key，即由多个字段联合组成主键，对于组合主键来说，在HBase底层会把主键的多个字段组合成rowkey显示，其它字段为HBase的qualifier显示。如上面test表，假设id和name为主键，创建表语句又变成:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">create table &quot;test&quot; (&quot;id&quot; varchar(20), &quot;name&quot; varchar(20) ,&quot;i&quot;.&quot;age&quot; varchar(20),constraint pk PRIMARY KEY(&quot;id&quot;,&quot;name&quot;));</div></pre></td></tr></table></figure></p>
<p>这样，假设插入一条数据:如下所示<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">upsert into &quot;test&quot; values (&apos;1&apos;,&apos;a&apos;,&apos;23&apos;);</div></pre></td></tr></table></figure></p>
<p>在HBase中，rowkey即为<code>&quot;1a&quot;</code>, i:age 为 23。这里，可能大家对双引号有点疑问，对于Phoenix来说，加了引号的话，不管是表还是字段名，会变成大小写敏感，不加的话，会统一转换成大写字母。</p>
<h2 id="2-4-Phoenix所支持的语法"><a href="#2-4-Phoenix所支持的语法" class="headerlink" title="2.4 Phoenix所支持的语法"></a>2.4 Phoenix所支持的语法</h2><p>目前Phoenix已经支持关系型数据库的大部分语法，如下图所示：<br><img src="/2017/11/11/phoenix-introduction/phoenix_grammer.png" alt="图4.Phoenix 语法"><br>具体语法用法可参考<a href="http://phoenix.apache.org/language/index.html" target="_blank" rel="external">Phoenix官网</a>,写得比较详细。</p>
<h1 id="三、-Phoenix二级索引"><a href="#三、-Phoenix二级索引" class="headerlink" title="三、 Phoenix二级索引"></a>三、 Phoenix二级索引</h1><p>我相信，二级索引这个特性应该是大部分用户引入Phoenix主要考虑的因素之一。HBase因其历史原因只支持rowkey索引，当使用rowkey来查询数据时可以很快定位到数据位置。现实中，业务查询需求条件往往比较复杂，带有多个查询字段组合，如果用HBase查的话，只能全表扫描进行过滤，效率很低。而Phoenix支持除rowkey外的其它字段的索引创建，即二级索引，查询效率可大幅提升。</p>
<h2 id="3-1-索引类别"><a href="#3-1-索引类别" class="headerlink" title="3.1 索引类别"></a>3.1 索引类别</h2><h3 id="3-1-1-Covered-Indexes"><a href="#3-1-1-Covered-Indexes" class="headerlink" title="3.1.1 Covered Indexes"></a>3.1.1 Covered Indexes</h3><p>从字面上可理解为覆盖索引，什么意思呢，即索引表中就包含你想要的全部字段数据，这样就只需要通过访问索引表而无需访问主表就能得到数据。创建方式如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">create index my_index on test (v1) include(v2);</div></pre></td></tr></table></figure></p>
<p>当执行<code>select v2 from test where v1=&#39;...&#39;</code>时，就只会查找索引表数据，不会去主表扫描。</p>
<h3 id="3-1-2-Global-Indexes"><a href="#3-1-2-Global-Indexes" class="headerlink" title="3.1.2 Global Indexes"></a>3.1.2 Global Indexes</h3><p>全局索引适用于读多写少的场景。全局索引在写数据时会消耗大量资源，所有对数据的增删改操作都会更新索引表，而索引表是分布在各个结点上的，性能会受到影响。好处就是，在读多的场景下如果查询的字段用到索引，效率会很快，因为可以很快定位到数据所在具体结点region上，对于写性能就很慢了，因为每写一次，需要更新所有结点上的索引表数据。创建方式如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">create index my_index on test (v1);</div></pre></td></tr></table></figure></p>
<p>如果执行`select v2 from test where v1=’…’， 实际是用不上索引的，因为v2不在索引字段中，对于全局索引来说，如果查询的字段不包含在索引表中，则还是会去全表扫描主表。</p>
<h3 id="3-1-3-Local-Indexes"><a href="#3-1-3-Local-Indexes" class="headerlink" title="3.1.3 Local Indexes"></a>3.1.3 Local Indexes</h3><p>局部索引适用于写多读少场景，和全局索引类似，Phoenix会在查询时自动选择是否使用索引。如果定义为局部索引，索引表数据和主表数据会放在同一regionserver上，避免写操作时跨节点写索引表带来的额外开销(如Global Indexes)。当使用局部索引查询时，即使查询字段不是索引字段，索引表也会正常使用，这和Global Indexes是有区别的。在4.8版本之前，所有局部索引数据存放在一个单独的共享表中，4.8之后是存储在主表的一个独立的列族中。因为是局部索引，所以在client端查询使用索引时，需要扫描每个结点上的索引表以得到数据所在具体region位置，当region多时，查询时耗会很高，所以查询性能比较低，适合读少写多场景。创建局部索引方式：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">create local index my_index on test (v1);</div></pre></td></tr></table></figure></p>
<h2 id="3-2-Mutable-Indexing-和Immutable-Indexing"><a href="#3-2-Mutable-Indexing-和Immutable-Indexing" class="headerlink" title="3.2 Mutable Indexing 和Immutable Indexing"></a>3.2 Mutable Indexing 和Immutable Indexing</h2><h3 id="3-2-1-IMMutable-Indexing"><a href="#3-2-1-IMMutable-Indexing" class="headerlink" title="3.2.1 IMMutable Indexing"></a>3.2.1 IMMutable Indexing</h3><p>不可变索引主要创建在不可变表上，适用于数据只写一次不会有Update等操作，在什么场景下会用到不可变索引呢，很经典的时序数据:<code>write once read many times</code>。在这种场景下，所有索引数据（primary和index)要么全部写成功，要么一个失败全都失败返回错误给客户端。不可变索引用到场景比较少，下面是创建不可变索引的方式：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">create table test (pk VARCHAR primary key,v1 VARCHAR, v2 VARCHAR) IMMUTABLE_ROWS=true;</div></pre></td></tr></table></figure></p>
<p>即在创建表时指定IMMUTABLE_ROWS参数为true，默认这个参数为false。如果想把不可变索引改为可变索引，可用alter修改：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">alter table test set IMMUTABLE_ROWS=false;</div></pre></td></tr></table></figure></p>
<h3 id="3-2-2-Mutable-Indexing"><a href="#3-2-2-Mutable-Indexing" class="headerlink" title="3.2.2 Mutable Indexing"></a>3.2.2 Mutable Indexing</h3><p>可变索引意思是在修改数据如Insert、Update或Delete数据时会同时更新索引。这里的索引更新涉及WAL，即主表数据更新时，会把索引数据也同步更新到WAL，只有当WAL同步到磁盘时才会去更新实际的primary/index数据，以保证当中间任何一个环节异常时可通过WAL来恢复主表和索引表数据。</p>
<h1 id="四、性能"><a href="#四、性能" class="headerlink" title="四、性能"></a>四、性能</h1><p>在官网，有作一个性能测试，主要是将Phoenix和Hive、Impala作一个对比。<br>先来看下和Hive的性能对比，测试基准如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">select count(1) from table over 10M and 100M rows. Data is 5 narrow columns. Number of Region Servers: 4 (HBase heap: 10GB, Processor: 6 cores @ 3.3GHz Xeon)</div></pre></td></tr></table></figure></p>
<p>测试结果：<br><img src="/2017/11/11/phoenix-introduction/phoenix_performance.png" alt="图6.Phoenix性能对比"><br>从图中可看出，带有Key过滤的Phoenix耗时最少，不带Key过滤的Phoenix和基于HDFS的Hive性能差不多，直接基于HBase的Hive性能最差。</p>
<p>再来看下和Impala的对比，测试基准如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">select count(1) from table over 1M and 5M rows. Data is 3 narrow columns. Number of Region Server: 1 (Virtual Machine, HBase heap: 2GB, Processor: 2 cores @ 3.3GHz Xeon)</div></pre></td></tr></table></figure></p>
<p>测试结果：<br><img src="/2017/11/11/phoenix-introduction/phoenix_performance_impala.png" alt="图7.Phoenix性能对比Impala"><br>从图中可看出，Impala执行时间比Phoenix长很多，原因大概有几点：Impala基于内存进行并行计算，容易内存吃紧，对HBase和HDFS的支持也还远远不够，性能比较差。</p>
<p>我在自己的HBase测试集群也作了下测试，主要测试数据插入和一些SQL操作的查询时耗。测试集群如下：</p>
<p><img src="/2017/11/11/phoenix-introduction/hbase_base.png" alt="图8.测试集群"></p>
<p>先来测试下插入100万记录的测试基准，如下所示：</p>
<blockquote>
<ul>
<li><p>1.创建基本表，表主键由4个字段组成，HOST字段称为<code>First PK</code>,DOMAIN为<code>Second PK</code>, 依此类推，SPLIT ON指定8个分区。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">CREATE TABLE IF NOT EXISTS %s (HOST CHAR(2) NOT NULL,</div><div class="line">DOMAIN VARCHAR NOT NULL, </div><div class="line">FEATURE VARCHAR NOT NULL,</div><div class="line">DATE DATE NOT NULL,</div><div class="line">USAGE.CORE BIGINT,</div><div class="line">USAGE.DB BIGINT,</div><div class="line">STATS.ACTIVE_VISITOR INTEGER</div><div class="line">CONSTRAINT PK PRIMARY KEY (HOST, DOMAIN, FEATURE, DATE))  </div><div class="line">SPLIT ON   (&apos;CSGoogle&apos;,&apos;CSSalesforce&apos;,&apos;EUApple&apos;,&apos;EUGoogle&apos;,&apos;EUSalesforce&apos;,&apos;NAApple&apos;,&apos;NAGoogle&apos;,&apos;NASalesforce&apos;)</div></pre></td></tr></table></figure>
</li>
<li><p>2.插入100万行记录</p>
</li>
<li><p>3.执行如下查询条件测试</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">Query # 1 - Count - SELECT COUNT(1) FROM PERFORMANCE_1000000;</div><div class="line">Query # 2 - Group By First PK - SELECT HOST FROM PERFORMANCE_1000000 GROUP BY HOST;</div><div class="line">Query # 3 - Group By Second PK - SELECT DOMAIN FROM PERFORMANCE_1000000 GROUP BY DOMAIN;</div><div class="line">Query # 4 - Truncate + Group By - SELECT TRUNC(DATE,&apos;DAY&apos;) DAY FROM PERFORMANCE_1000000 GROUP BY TRUNC(DATE,&apos;DAY&apos;);</div><div class="line">Query # 5 - Filter + Count - SELECT COUNT(1) FROM PERFORMANCE_1000000 WHERE CORE&lt;10;</div></pre></td></tr></table></figure>
</li>
</ul>
</blockquote>
<p>测试结果如下：</p>
<blockquote>
<ul>
<li><ol>
<li>插入100万条记录耗时70s</li>
</ol>
</li>
<li><ol>
<li>Query #1  耗时1.032s</li>
</ol>
</li>
<li><ol>
<li>Query #2  耗时0.025s</li>
</ol>
</li>
<li><ol>
<li>Query #3  耗时0.615s</li>
</ol>
</li>
<li><ol>
<li>Query #4  耗时0.608s</li>
</ol>
</li>
<li><ol>
<li>Query #5  耗时1.026s</li>
</ol>
</li>
</ul>
</blockquote>
<p>具体结果如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div></pre></td><td class="code"><pre><div class="line">csv columns from database.</div><div class="line">CSV Upsert complete. 1000000 rows upserted</div><div class="line">Time: 69.672 sec(s)</div><div class="line"></div><div class="line">                                COUNT(1) </div><div class="line">---------------------------------------- </div><div class="line">                                 1000000 </div><div class="line">Time: 1.032 sec(s)</div><div class="line"></div><div class="line">HO </div><div class="line">-- </div><div class="line">CS </div><div class="line">EU </div><div class="line">NA </div><div class="line">Time: 0.025 sec(s)</div><div class="line"></div><div class="line">DOMAIN                                   </div><div class="line">---------------------------------------- </div><div class="line">Apple.com                                </div><div class="line">Google.com                               </div><div class="line">Salesforce.com                           </div><div class="line">Time: 0.615 sec(s)</div><div class="line"></div><div class="line">DAY                     </div><div class="line">----------------------- </div><div class="line">2018-01-28 00:00:00.000 </div><div class="line">2018-01-29 00:00:00.000 </div><div class="line">2018-01-30 00:00:00.000 </div><div class="line">2018-01-31 00:00:00.000 </div><div class="line">2018-02-01 00:00:00.000 </div><div class="line">2018-02-02 00:00:00.000 </div><div class="line">2018-02-03 00:00:00.000 </div><div class="line">2018-02-04 00:00:00.000 </div><div class="line">2018-02-05 00:00:00.000 </div><div class="line">2018-02-06 00:00:00.000 </div><div class="line">2018-02-07 00:00:00.000 </div><div class="line">2018-02-08 00:00:00.000 </div><div class="line">2018-02-09 00:00:00.000 </div><div class="line">Time: 0.608 sec(s)</div><div class="line"></div><div class="line">                                COUNT(1) </div><div class="line">---------------------------------------- </div><div class="line">                                   20209 </div><div class="line">Time: 1.026 sec(s)</div></pre></td></tr></table></figure></p>
<p>还作了下三种不同数量级下的性能对比，作了5种SQL查询操作对比，如上测试基准第3条所描述的查询条件，结果如下：<br><img src="/2017/11/11/phoenix-introduction/phoenix_test.png" alt="图9.Phoenix不同数据量级测试对比"></p>
<p>从结果看，随着数量级的增加，查询时耗也随之增加，有一个例外，就是当用First PK索引字段作聚合查询时，用时相差不大。总的来说，Phoenix在用到索引时查询性能会比较好。那对于Count来说，如果不用Phoenix,用HBase自带的Count耗时是怎样的呢，测了一下，HBase Count 100万需要33s, 500万需要139s,1000万需要284s，性能还是很差的。对于大表来说基本不能用Count来统计行数，还得依赖于基于Coprocessor机制来统计。</p>
<p>从上面测试来看下，Phoenix的性能不能说最好，也存在各种问题，就如开篇说的，版本不稳定，BUG过多，容易影响集群稳定性。</p>
<h1 id="五、总结"><a href="#五、总结" class="headerlink" title="五、总结"></a>五、总结</h1><p>总的来说，目前并没有一种很完美的方案来解决SQL查询、二级索引问题，都或多或少存在各种问题。不过HBase的Coprocessor是个好东西，很多功能可以基于此特性进行二次开发，后续可以深入研究一下。</p>
<h1 id="六、参考"><a href="#六、参考" class="headerlink" title="六、参考"></a>六、参考</h1><p>[1] <a href="https://community.hortonworks.com/articles/61705/art-of-phoenix-secondary-indexes.html" target="_blank" rel="external">https://community.hortonworks.com/articles/61705/art-of-phoenix-secondary-indexes.html</a></p>
<p>[2] <a href="https://github.com/forcedotcom/phoenix/wiki/Secondary-Indexing" target="_blank" rel="external">https://github.com/forcedotcom/phoenix/wiki/Secondary-Indexing</a></p>
<p>[3] <a href="http://phoenix.apache.org/secondary_indexing.html" target="_blank" rel="external">http://phoenix.apache.org/secondary_indexing.html</a></p>
</div><div class="article-footer-copyright">版权声明:本文由ballen原创，转载请注明出处, 本博客地址:zendwind.com</div><iframe src="/donate/?AliPayQR=null&amp;WeChatQR=/img/WeChatQR.png&amp;GitHub=null&amp;BTCQR=null&amp;BTCKEY=null&amp;PayPal=null" style="overflow-x:hidden;overflow-y:hidden; border:0xp none #fff; min-height:240px; width:100%;" frameborder="0" scrolling="no"></iframe><div class="tags"><a href="/tags/HBase/">HBase</a></div><div class="post-nav"><a href="/2018/05/15/hadoop-small-file-storage/" class="pre">【原】Hadoop小文件存储方案</a><a href="/2017/10/15/python-read-dump/" class="next">【原】Python解析mysqldump文件</a></div><div id="container"></div><link rel="stylesheet" href="/css/default.css?v=0.0.0"><script src="/js/gitment.browser.js?v=0.0.0"></script><script>var gitment = new Gitment({
  owner: 'ballwql## Your GitHub ID, e.g. username',
  repo: 'ballwql.github.io## The repository to store your comments, make sure you're the repo's owner, e.g. imsun.github.io',
  oauth: {
    client_id: 'e1067ce8b7aaa1a88a45## GitHub client ID, e.g. 75752dafe7907a897619',
    client_secret: '5f4e1d8d82c95a8610d5d19d51e97b7926fd5e71## GitHub client secret, e.g. ec2fb9054972c891289640354993b662f4cccc50',
  },
})
gitment.render('container')
</script></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form action="//www.baidu.com/baidu" method="get" accept-charset="utf-8" target="_blank" class="search-form"><input type="search" name="word" maxlength="20" placeholder="Search"/><input type="hidden" name="si" value="http://zendwind.com"/><input name="tn" type="hidden" value="bds"/><input name="cl" type="hidden" value="3"/><input name="ct" type="hidden" value="2097152"/><input name="s" type="hidden" value="on"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/HBase/">HBase</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Python/">Python</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/hadoop/">hadoop</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/HBase/" style="font-size: 15px;">HBase</a> <a href="/tags/hadoop/" style="font-size: 15px;">hadoop</a> <a href="/tags/python/" style="font-size: 15px;">python</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2018/05/15/hadoop-small-file-storage/">【原】Hadoop小文件存储方案</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/11/11/phoenix-introduction/">【原】浅谈Phoenix在HBase中的应用</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/10/15/python-read-dump/">【原】Python解析mysqldump文件</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/10/11/hbase-read-write-exception-summary/">【原】HBase读写异常问题总结</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/10/08/hadoop-ha-qjm/">【原】Hadoop HA机制学习</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/10/08/hdfs-multi-replicas-analysis/">揭开HDFS多副本的面纱</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/09/27/first-blog/">开篇导言</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://www.cnblogs.com/ballwql" title="Cnblogs" target="_blank">Cnblogs</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2018 <a href="/." rel="nofollow">ballen博客.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a id="rocket" href="#top" class="show"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.1.20/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.1.20/jquery.fancybox.min.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>