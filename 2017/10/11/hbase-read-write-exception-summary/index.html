<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>【原】HBase读写异常问题总结 | ballen博客</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/7.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.2.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="stylesheet" type="text/css" href="/css/copyright.css?v=0.0.0"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">【原】HBase读写异常问题总结</h1><a id="logo" href="/.">ballen博客</a><p class="description">专注于智能运维&amp;大数据</p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div id="layout" class="pure-g"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">【原】HBase读写异常问题总结</h1><div class="post-meta">Oct 11, 2017<span> | </span><span class="category"><a href="/categories/HBase/">HBase</a></span><script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> 阅读</span></span></div><div class="post-content"><p>国庆期间，HBase集群出现一次比较严重的问题，故障期间，业务方反馈查询大量超时，由于涉及重点业务查询，影响也是比较大的。下面复盘一下问题发生过程并作相应分析<br><a id="more"></a></p>
<h1 id="一、问题描述"><a href="#一、问题描述" class="headerlink" title="一、问题描述"></a>一、问题描述</h1><p>10月6号傍晚从18:00点开始，业务陆续反馈查询HBase历史数据异常，出现大量超时，下面是当时的业务成功率曲线。整个过程经历了5次成功率下降的阶段，这是之前未出现过的。<br><img src="/2017/10/11/hbase-read-write-exception-summary/business_success_rate.png" alt="图1. 业务成功率曲线"></p>
<p>在查看重点业务组所在机器的写监控曲线，故障期间重点表基本不可写：<br><img src="/2017/10/11/hbase-read-write-exception-summary/hbase_write_request.png" alt="图2.重点表写曲线"></p>
<p>同时重点表的读也是异常的，基本不可读：<br><img src="/2017/10/11/hbase-read-write-exception-summary/hbase_read_request.png" alt="图3.重点表读曲线"></p>
<h1 id="二、原因分析"><a href="#二、原因分析" class="headerlink" title="二、原因分析"></a>二、原因分析</h1><h2 id="2-1-采集分析"><a href="#2-1-采集分析" class="headerlink" title="2.1 采集分析"></a>2.1 采集分析</h2><p>查看数据采集曲线，未看到有表数据发生延迟采集或DB数据源故障情况，排除采集异常。</p>
<h2 id="2-2-消费分析"><a href="#2-2-消费分析" class="headerlink" title="2.2 消费分析"></a>2.2 消费分析</h2><p>查看数据消费曲线，发现重点业务的所有表消费曲线延迟严重，消费者本身无报错产生，查看消费日志写得很慢，既然消费未报错又写得慢，问题应该出现在HBase端。</p>
<h2 id="2-3-HBase分析"><a href="#2-3-HBase分析" class="headerlink" title="2.3 HBase分析"></a>2.3 HBase分析</h2><h3 id="2-3-1-第一次-amp-第二次异常原因分析"><a href="#2-3-1-第一次-amp-第二次异常原因分析" class="headerlink" title="2.3.1 第一次&amp;第二次异常原因分析"></a>2.3.1 第一次&amp;第二次异常原因分析</h3><p>根据经验，HBase读写异常很大程度上和机器异常有关。首先，找出重点业务所在的机器列表，并根据所采集的监控曲线，看了下这些机器的处理时耗，如下图所示：<br><img src="/2017/10/11/hbase-read-write-exception-summary/machine_queue_process_time.png" alt="图4.机器处理时耗"><br>从图中，可看出在故障期间，这些机器的处理时耗异常，是所有机器都异常还是只有个别机器处理异常呢，继续从上面图查看分布状态图，如下图所示：<br><img src="/2017/10/11/hbase-read-write-exception-summary/machine_queue_process_time_ip.png" alt="图5.单机处理时耗"><br>从图可以看出，确实有一台机器的处理时耗比其它机器都高，找到异常机器后，从tnm2上看了下单机性能情况，如下图所示：<br><img src="/2017/10/11/hbase-read-write-exception-summary/machine_performance.png" alt="图6.单机性能曲线"><br>从图中，可以看出，异常机器在18:00附近各项指标也是异常的，磁盘IO、CPU负载、SWAP内存都表现异常，说明机器确实存在问题。那是什么原因导致的机器负载异常呢，继续登陆机器查看日志情况，在18:00附近左右，找到如下一个异常：<br><img src="/2017/10/11/hbase-read-write-exception-summary/machine_hbase_log.png" alt="图7.异常机器日志异常"><br>从多个异常描述中，都发现一个共性现象，就是集中在t_tcbankroll_list_auid_201707这个表上，看日志信息是这个表在作合并，查看了下合并任务，发现确实在这天有一条合并定时任务，合并任务主要是合并3个月前的表，正好是上述7月份的表，是不是合并存在异常呢，继续看了下监控中关于该异常IP的合并队列,发现在18:00合并队列高达59000，即有几万个合并任务等着被执行，之后合并队列表现异常，机器读写也异常，说明确实合并有问题。<br><img src="/2017/10/11/hbase-read-write-exception-summary/machine_compact_queue.png" alt="图8.异常机器合并队列"><br>为什么合并会有问题呢？进一步看了下异常表的region的大小，发现大小严重不均，集中在两个端，8G和20G左右。合并出问题应该是出在合并20G大小的region时出现的问题。<br><img src="/2017/10/11/hbase-read-write-exception-summary/hbase_table_region.png" alt="图9.异常表region文件数"><br>是在合并哪个Region的时候出的问题呢，再看下图7中异常机器的日志，发现<code>324c091cfd8e944507ae645ddeda78e2</code>这个region合并时出的问题，同时这个region的大小在图9中正好属于20G那个范围的，验证了上述猜想。<br>那为什么合并大Region过程出现问题了呢，再从18:00异常时间点附近看了下日志，如下所示</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">2017-10-06 18:22:36,280 WARN  [regionserver60020] util.Sleeper: We slept 24555ms instead of 3000ms, this is likely due to a long garbage collecting pause and it&apos;s usually bad, see，http://hbase.apache.org/book.html#trouble.rs.runtime.zkexpired</div><div class="line">2017-10-06 18:22:36,280 WARN  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 22680ms</div><div class="line">GC pool &apos;ParNew&apos; had collection(s): count=1 time=247ms</div><div class="line">GC pool &apos;ConcurrentMarkSweep&apos; had collection(s): count=1 time=22712ms</div></pre></td></tr></table></figure>
<p>这种迹象很明显就是在作FullGC，频繁的GC过程阻塞了读写进程， 在这个时间段内，看了下JVM堆内存的使用量，发现异常的高，如下所示：<br><img src="/2017/10/11/hbase-read-write-exception-summary/machine_jvm.png" alt="图10.异常机器JVM堆内存使用"><br>了解FullGC的人都知道，FullGC期间，集群读写会被堵塞，如图7所示客户端连接会出现超时异常，再加上我们机器本身性能比较差，导致FullGC过程中，机器IO、网络、CPU、内存和SWAP等都出现异常，阻塞了集群读写，影响了重点业务的查询。知道啥原因后，直接把机器剔除停掉regionserver进程，业务读写开始恢复正常。</p>
<p>好景不长，只过了不到20min, 第二次异常突然降临，在18点56时，业务查询成功率又开始降低。回想一下第一次故障，只是把当时有异常的机器剔除，但没考虑的是异常表的合并任务并未终结，只是把合并异常的任务转移到其它机器，重点业务组机器并未终止合并，即其它机器的负载并未得到有效缓解，看监控曲线发现，此时另一台机器出现异常，如图10所示，该机集群处理时耗明显高于其它机器，和第一次样，把异常机器剔除后业务恢复正常。<br><img src="/2017/10/11/hbase-read-write-exception-summary/machine_process_time.png" alt="图11.异常机器时耗曲线"></p>
<h3 id="2-3-2-第三次-amp-第四次-amp-第五次故障分析"><a href="#2-3-2-第三次-amp-第四次-amp-第五次故障分析" class="headerlink" title="2.3.2 第三次&amp;第四次&amp;第五次故障分析"></a>2.3.2 第三次&amp;第四次&amp;第五次故障分析</h3><p>前面2次的故障还好，都还是单机异常所致，后面出现的两次异常却是多机同时出现异常，此时单纯剔除单台机器已无法解决问题，因重点业务组所在机器数量比较少，再重新扩机器进去也不太可行，如果都剔除那读写就完全中止了，影响更大。<br>上面说到，其实前两次故障都没解决合并异常的本质问题，合并还在继续，合并队列也维持在一个高位，此时对整个机器组来说压力都是非常大的，机器资源大量被用于作合并，导致其它操作无法有效获取资源。只能想其它办法解决。<br>既然合并队列一直在高位，有什么办法可以降低合并队列长度呢，社区<code>HBase-17928</code>补丁给我们带来了福音，它要解决的就是当表合并异常或在很长时间合并都未完成的场景。使用方式如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">clear_queues &apos;SERVERNAME&apos;, [&apos;QUEUE_NAME1&apos;,&apos;QUEUE_NAME2&apos;]</div></pre></td></tr></table></figure></p>
<p>其中，SERVERNAME表示regionserver，形式如<code>ip,port,timestamp</code>，QUEUE_NAME表示队列的长度，可以为<code>short,long</code>。对于我们来说，采用的是直接清理到机器的合并队列，即如果机器10.x.x.x有问题，清理如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">clear_queues &apos;10.x.x.x,60020,1491511804929&apos;</div></pre></td></tr></table></figure></p>
<p>在清理部分合并队列过长的机器之后，集群读写恢复了部分，但还未全部恢复，导致了第四次业务查询还是受影响，因为清理时没把所有机器清理干净，所以异常还未完全解决。<br>第四次故障之后，对剩下的机器也全部清理了一遍队列，同时还作了一个操作，就是<strong>把异常表移出重点业务组，让合并在组外的机器进行</strong>，这样能尽量避免异常表对其它表影响。</p>
<p>在做完上述动作之后，隔了不到10min, 第5次故障又如期而至，充分验证了墨菲定律，不想发生的偏要发生。第5次故障是什么原因呢，从监控曲线上面看，根据第一次和第二次的故障分析，总结出此次也是因单机故障引起的，首先做的就是剔除该异常机器，但因负载问题，一直登录异常，耽误了异常恢复原因，等剔除后业务终于开始恢复正常。</p>
<p>在观察一段时间后，整个重点业务组暂时运行稳定，此时因踢掉了多台机器，组内的10几台机器的region已经分布不均，有潜在风险，需要考虑把之前剔除机器上的region还原。正常的还原方法是，如果regionserver剔除是按正规流程剔除的话，会记录该机器上有什么region，然后机器恢复后把region再move回来即可；不过，像我们这种情况，属于紧急剔除，踢之前没考虑记录region信息，需要考虑从其它渠道来恢复信息，还有一种方法是从日志恢复，日志恢复方法就是从master上去找剔除时间点开始往后带关键字如<code>Transition和Offline</code>等关键字的日志，然后找出region move回到原机器即可。</p>
<h1 id="三、故障梳理"><a href="#三、故障梳理" class="headerlink" title="三、故障梳理"></a>三、故障梳理</h1><p>经过上述一系列的分析和采取的一系列措施，故障得以恢复，整个故障原因总结如下：</p>
<blockquote>
<ul>
<li>合并任务异常，触发机器频繁GC，机器负载异常</li>
<li>GC阻塞了DFSClient的读写请求发送</li>
<li>HDFS服务端报大量的读写Socket连接超时并关闭client请求连接</li>
</ul>
</blockquote>
<p>故障措施总结：</p>
<blockquote>
<ul>
<li>剔除异常机器regionserver进程</li>
<li>清理异常机器的合并队列</li>
<li>恢复region回原机器</li>
</ul>
</blockquote>
<h1 id="四、故障反思"><a href="#四、故障反思" class="headerlink" title="四、故障反思"></a>四、故障反思</h1><p>此次故障引发的连锁反应之前也没遇到过，耽误了很多时间，也侧面反应出自己对这些异常缺乏足够的认识，通过此次排查也让自己对regionserver异常有一个更清楚的了解，后续在运维过程中需要更多关注以下一些点：</p>
<blockquote>
<ul>
<li>出现异常，以业务恢复为先，先保留事故现场日志，该剔除的剔除</li>
<li>监控完善，一直在说监控问题，但监控事项总有些纰漏，需在这块优化加强，尤其是巡检机制</li>
<li>业务重点表隔离细化，虽然已经做了相应隔离，但分级还是不够细化，需针对重点业务再作分级隔离</li>
</ul>
</blockquote>
</div><div class="article-footer-copyright">版权声明:本文由ballen原创，转载请注明出处, 本博客地址:zendwind.com</div><iframe src="/donate/?AliPayQR=null&amp;WeChatQR=/img/WeChatQR.png&amp;GitHub=null&amp;BTCQR=null&amp;BTCKEY=null&amp;PayPal=null" style="overflow-x:hidden;overflow-y:hidden; border:0xp none #fff; min-height:240px; width:100%;" frameborder="0" scrolling="no"></iframe><div class="tags"><a href="/tags/HBase/">HBase</a></div><div class="post-nav"><a href="/2017/10/15/python-read-dump/" class="pre">【原】Python解析mysqldump文件</a><a href="/2017/10/08/hadoop-ha-qjm/" class="next">【原】Hadoop HA机制学习</a></div><div id="container"></div><link rel="stylesheet" href="/css/default.css?v=0.0.0"><script src="/js/gitment.browser.js?v=0.0.0"></script><script>var gitment = new Gitment({
  owner: 'ballwql## Your GitHub ID, e.g. username',
  repo: 'ballwql.github.io## The repository to store your comments, make sure you're the repo's owner, e.g. imsun.github.io',
  oauth: {
    client_id: 'e1067ce8b7aaa1a88a45## GitHub client ID, e.g. 75752dafe7907a897619',
    client_secret: '5f4e1d8d82c95a8610d5d19d51e97b7926fd5e71## GitHub client secret, e.g. ec2fb9054972c891289640354993b662f4cccc50',
  },
})
gitment.render('container')
</script></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form action="//www.baidu.com/baidu" method="get" accept-charset="utf-8" target="_blank" class="search-form"><input type="search" name="word" maxlength="20" placeholder="Search"/><input type="hidden" name="si" value="http://zendwind.com"/><input name="tn" type="hidden" value="bds"/><input name="cl" type="hidden" value="3"/><input name="ct" type="hidden" value="2097152"/><input name="s" type="hidden" value="on"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/HBase/">HBase</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Python/">Python</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/hadoop/">hadoop</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/work/">work</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/hadoop/" style="font-size: 15px;">hadoop</a> <a href="/tags/HBase/" style="font-size: 15px;">HBase</a> <a href="/tags/python/" style="font-size: 15px;">python</a> <a href="/tags/work/" style="font-size: 15px;">work</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2018/08/22/first-english-blog/">Try to write technical blog with english</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/05/15/hadoop-small-file-storage/">【原】Hadoop小文件存储方案</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/11/11/phoenix-introduction/">【原】浅谈Phoenix在HBase中的应用</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/10/15/python-read-dump/">【原】Python解析mysqldump文件</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/10/11/hbase-read-write-exception-summary/">【原】HBase读写异常问题总结</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/10/08/hadoop-ha-qjm/">【原】Hadoop HA机制学习</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/10/08/hdfs-multi-replicas-analysis/">揭开HDFS多副本的面纱</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/09/27/first-blog/">开篇导言</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://www.cnblogs.com/ballwql" title="Cnblogs" target="_blank">Cnblogs</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2018 <a href="/." rel="nofollow">ballen博客.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a id="rocket" href="#top" class="show"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.1.20/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.1.20/jquery.fancybox.min.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>